{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Project 3 on Fuzzy system</center>\n",
    "\n",
    "Subject: Fuzzy C-mean clustering\n",
    "\n",
    "Name: Hesam Mousavi\n",
    "\n",
    "Student number: 9931155\n",
    "\n",
    "Master student\n",
    "\n",
    "<p align=\"center\">\n",
    " <img src=\"report/cmean.png\">\n",
    "</p>\n",
    "\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Config({\n",
    "tex2jax: {\n",
    "inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n",
    "processEscapes: true},\n",
    "jax: [\"input/TeX\",\"input/MathML\",\"input/AsciiMath\",\"output/CommonHTML\"],\n",
    "extensions: [\"tex2jax.js\",\"mml2jax.js\",\"asciimath2jax.js\",\"MathMenu.js\",\"MathZoom.js\",\"AssistiveMML.js\", \"[Contrib]/a11y/accessibility-menu.js\"],\n",
    "TeX: {\n",
    "extensions: [\"AMSmath.js\",\"AMSsymbols.js\",\"noErrors.js\",\"noUndefined.js\"],\n",
    "equationNumbers: {\n",
    "autoNumber: \"AMS\"\n",
    "}\n",
    "}\n",
    "});\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fcmeans import FCM\n",
    "from my_io import read_dataset_to_X_and_y\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Class to easily have all the variables\n",
    "\n",
    "I like to have my variable all together so I build a class and named it\n",
    "UniSet(short form of universal set)\n",
    "\n",
    "Read dataset with my function on my_io module that can shuffle sample and\n",
    "correct missing values also normalized the feature.  \n",
    "\n",
    "In here I shuffle data and use class-mean for the missing values then\n",
    "normalized it with the z-score method(zero-mean unit-variance)\n",
    "\n",
    "I use all the features(12) and change sex from m, f to 0, 1 (actually I map\n",
    "each string to a specific number in my_io module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole dataset is (615, 12) matrix\n"
     ]
    }
   ],
   "source": [
    "class UniSet():\n",
    "    def __init__(self, file, range_feature, range_label,\n",
    "                 normalization='scaling', min_value=0.1, max_value=1,\n",
    "                 shuffle=False, about_nan='class_mean'):\n",
    "        np.random.seed(1)\n",
    "        sample, label = read_dataset_to_X_and_y(\n",
    "            file, range_feature, range_label, normalization, min_value, max_value,\n",
    "            shuffle=shuffle, about_nan=about_nan)\n",
    "        self.universal = sample.astype(float)\n",
    "        self.label = label\n",
    "        self.number_of_feature = sample.shape[1]\n",
    "        self.size_of_universal = sample.shape[0]\n",
    "        self.diffrent_label = np.unique(label)\n",
    "        self.number_of_diffrent_label = self.diffrent_label.shape[0]\n",
    "\n",
    "\n",
    "uni_total = UniSet(\n",
    "    'dataset/hcvdat0.csv', (2, 14), (1, 2),\n",
    "    normalization='scaling', shuffle=True, about_nan='class_mean')\n",
    "\n",
    "\n",
    "print(f'The whole dataset is {uni_total.universal.shape} matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Details \n",
    ">\n",
    "> In my_io module I have a function named read_dataset_to_X_and_y\n",
    ">  that get dataset file, range of attributes that are our features,\n",
    ">  range of attributes that are our labels, normalization which is\n",
    ">  our normalization method, shuffle which if be True our samples be\n",
    ">  shuffled, and about_nan that can be \"delete\" which delete samples\n",
    ">  with NA values or \"class_mean\" which replace NA values with mean of\n",
    ">  that feature in the sample class\n",
    ">\n",
    "> Also as I mentioned above this function can get string attributes too\n",
    ">  by mapping each string to a specific value so now our labels $\\in [0, 4]$\n",
    ">\n",
    "> I change NA value with class-mean because It doesn't change the\n",
    ">  similarity(or distance) of two samples in one class \n",
    ">\n",
    "> In my class, I have all things that I'll need such as universal\n",
    ">  (sample data), their label, number of features, size of universal\n",
    ">  (dataset), different labels (unique labels), and number of different labels.\n",
    ">\n",
    "> Our labels in this dataset is attributed [1, 2) and features are attributed\n",
    ">  [2, 14) (12 features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the whole dataset to Train and Test\n",
    "\n",
    "As I shuffle the dataset before, now I just consider the first 80%\n",
    "of the data for the train and the rest for the test case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is (492, 12) matrix\n",
      "The test dataset is (123, 12) matrix\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(universe: UniSet, train_size: float) -> list[UniSet]:\n",
    "    train = deepcopy(universe)\n",
    "    test = deepcopy(universe)\n",
    "    train.size_of_universal = \\\n",
    "        int(universe.size_of_universal*train_size)\n",
    "    train.universal = \\\n",
    "        universe.universal[0:train.size_of_universal]\n",
    "    train.label = \\\n",
    "        universe.label[0:train.size_of_universal]\n",
    "    test.size_of_universal = (\n",
    "        universe.size_of_universal - train.size_of_universal)\n",
    "    test.universal = \\\n",
    "        universe.universal[train.size_of_universal:]\n",
    "    test.label = \\\n",
    "        universe.label[train.size_of_universal:]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "uni_train, uni_test = split_train_test(uni_total, 0.8)\n",
    "print(f'The train dataset is {uni_train.universal.shape} matrix')\n",
    "print(f'The test dataset is {uni_test.universal.shape} matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Details \n",
    ">\n",
    "> I create two classes for train and test by copying the total set and\n",
    "just changing universal, level, and size of universal for both train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our parameters\n",
    "\n",
    "$\\mu_{i, j}$: the probability that the jth data point belongs to the ith cluster which \n",
    "the sum of $\\mu_{i, j}$ over C cluster centers is 1 for every data point j\n",
    "\n",
    "$c_{i}$: the center of the ith cluster\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    " <img src=\"report/parameter.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function\n",
    "$$J=\\sum_{i=1}^{C} \\sum_{j=1}^{N} \\mu_{i j}^{m}\\left\\|x_{j}-c_{i}\\right\\|^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "I use **Confusion matrix** to find the label of clusters (argmax in each row)\n",
    "and then choose f1-score as accuracy metric because as $\\alpha$ increase\n",
    "precision increase and recall decrease and I want to find $\\alpha$ that satisfy both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gold_label: np.ndarray, predict_label: np.ndarray,\n",
    "             method: str = 'f1-score') -> float:\n",
    "    diffrent_label_in_gold_label = np.unique(gold_label)\n",
    "    diffrent_label_in_predict_label = np.unique(predict_label)\n",
    "    confusion_matrix = np.array(\n",
    "        list(map(lambda k: list(map(\n",
    "            lambda s: sum((predict_label == k)*(gold_label == s))[0],\n",
    "            diffrent_label_in_gold_label)),\n",
    "            diffrent_label_in_predict_label)))\n",
    "    precision = np.sum(\n",
    "        np.max(confusion_matrix, axis=1)) / np.sum(confusion_matrix)\n",
    "    recall = np.sum(\n",
    "        np.max(confusion_matrix, axis=0)) / np.sum(confusion_matrix)\n",
    "    if(method == 'precision'):\n",
    "        return precision\n",
    "    if(method == 'recall'):\n",
    "        return recall\n",
    "    if(method == 'f1-score'):\n",
    "        return 2 * ((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Details \n",
    "> \n",
    "> ##### Confusion matrix\n",
    "> \n",
    "> <p align=\"center\">\n",
    ">  <img src=\"report/confusion-matrix.png\">\n",
    "> </p>\n",
    "> \n",
    "> Its $(K * S)$ matrix that $a_{k, s}=$ total number of samples clustered\n",
    ">  to the kᵗʰ cluster and belongs to the sᵗʰ class.\n",
    ">  $$\\text { Precision }=\\frac{\\sum_{k}\n",
    "\\max _{s}\\left\\{a_{k s}\\right\\}}{\\sum_{k} \\sum_{s} a_{k s}}$$\n",
    ">  $$\\operatorname{Recall}=\\frac{\\sum_{s}\n",
    "\\max _{k}\\left\\{a_{k s}\\right\\}}{\\left(\\sum_{k} \\sum_{s} a_{k s}+U\\right)}$$\n",
    ">  $$F1-score=2 \\times \\frac{\\text\n",
    "{ Precision } \\times \\text { Recall }}{\\text { Precision }+\\text { Recall }}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcm = FCM(n_clusters=5)\n",
    "fcm.fit(uni_train.universal)\n",
    "# outputs\n",
    "fcm_centers = fcm.centers\n",
    "# fcm_labels = fcm.predict(uni_test.universal)\n",
    "fcm_labels = fcm.predict(uni_test.universal)\n",
    "fcm_labels = fcm_labels.reshape((-1,1))\n",
    "sum(fcm_labels == uni_test.label)\n",
    "# evaluate(uni_test.label, fcm_labels)\n",
    "# np.unique(fcm_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skfuzzy as fuzz\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cmeans(uni_train.universal.T, 5, 2, 0.005, 1000)\n",
    "fuzz_pre = fuzz.cmeans_predict(uni_test.universal.T, cntr, 2, 0.005, 1000)\n",
    "prob_fuzz = fuzz_pre[0].T\n",
    "label_fuzz = np.argmax(prob_fuzz, axis=1).reshape((-1, 1))\n",
    "sum(label_fuzz == uni_test.label)\n",
    "# evaluate(uni_test.label, label_fuzz)\n",
    "# np.unique(label_fuzz, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pause\n"
     ]
    }
   ],
   "source": [
    "print('pause')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Thanks for your time</center>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
